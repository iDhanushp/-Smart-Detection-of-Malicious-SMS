#!/usr/bin/env python3
"""
Detailed Analysis of Comprehensive Test Results
Focus on edge cases and potential improvements
"""

import pandas as pd
import numpy as np
from three_class_detector import ThreeClassSMSDetector

def analyze_edge_cases():
    """Analyze borderline and potentially misclassified messages"""
    print("üîç DETAILED EDGE CASE ANALYSIS")
    print("=" * 60)
    
    # Load the comprehensive test results
    try:
        df = pd.read_csv("comprehensive_test_results_2000.csv")
    except FileNotFoundError:
        print("‚ùå Test results file not found. Run comprehensive_test.py first.")
        return
    
    print(f"Analyzing {len(df)} test results...")
    
    # 1. Borderline cases (confidence 0.4-0.6)
    borderline = df[(df['confidence'] >= 0.4) & (df['confidence'] <= 0.6)]
    print(f"\nüü° BORDERLINE CASES ({len(borderline)} messages)")
    print("These need manual review:")
    print("-" * 50)
    
    for idx, row in borderline.head(10).iterrows():
        print(f"\nMessage: {row['text'][:80]}...")
        print(f"Sender: {row['sender']}")
        print(f"Prediction: {row['prediction']} (Confidence: {row['confidence']:.2f})")
        print(f"Probabilities: F={row['fraud_prob']:.2f}, S={row['spam_prob']:.2f}, L={row['legit_prob']:.2f}")
    
    # 2. High confidence fraud (potential false positives to review)
    high_fraud = df[(df['prediction'] == 'FRAUD') & (df['confidence'] > 0.7)]
    print(f"\nüö® HIGH CONFIDENCE FRAUD ({len(high_fraud)} messages)")
    print("Review these for false positives:")
    print("-" * 50)
    
    for idx, row in high_fraud.iterrows():
        print(f"\nMessage: {row['text'][:80]}...")
        print(f"Sender: {row['sender']}")
        print(f"Confidence: {row['confidence']:.2f}")
        print(f"Risk Factors: {row['risk_factors']}")
    
    # 3. Service messages classified as spam (potential false positives)
    service_spam = df[
        (df['prediction'] == 'SPAM') & 
        (df['sender'].str.contains(r'^[A-Z]{2,6}-', na=False))
    ]
    print(f"\n‚ö†Ô∏è SERVICE MESSAGES CLASSIFIED AS SPAM ({len(service_spam)} messages)")
    print("These might be false positives:")
    print("-" * 50)
    
    for idx, row in service_spam.head(10).iterrows():
        print(f"\nMessage: {row['text'][:80]}...")
        print(f"Sender: {row['sender']}")
        print(f"Confidence: {row['confidence']:.2f}")
        print(f"Reasoning: {row['reasoning']}")
    
    # 4. Phone numbers classified as fraud/spam
    phone_threats = df[
        (df['sender'].str.match(r'^\+?\d{10,}$', na=False)) & 
        (df['prediction'].isin(['FRAUD', 'SPAM']))
    ]
    print(f"\nüì± PHONE NUMBERS AS FRAUD/SPAM ({len(phone_threats)} messages)")
    print("Personal numbers flagged as threats:")
    print("-" * 50)
    
    for idx, row in phone_threats.head(5).iterrows():
        print(f"\nMessage: {row['text'][:80]}...")
        print(f"Sender: {row['sender']}")
        print(f"Prediction: {row['prediction']} (Confidence: {row['confidence']:.2f})")
    
    return {
        'borderline_count': len(borderline),
        'high_fraud_count': len(high_fraud),
        'service_spam_count': len(service_spam),
        'phone_threats_count': len(phone_threats)
    }

def sender_based_analysis():
    """Analyze classification patterns by sender type"""
    print(f"\nüìä SENDER-BASED CLASSIFICATION ANALYSIS")
    print("=" * 60)
    
    try:
        df = pd.read_csv("comprehensive_test_results_2000.csv")
    except FileNotFoundError:
        print("‚ùå Test results file not found.")
        return
    
    # Categorize senders
    def categorize_sender(sender):
        sender_str = str(sender)
        if sender_str == 'unknown' or sender_str == 'nan':
            return 'Unknown/Kaggle'
        elif sender_str.startswith('+') or sender_str.isdigit():
            return 'Phone Number'
        elif '-' in sender_str and len(sender_str.split('-')[0]) <= 6:
            return 'Service Code'
        elif sender_str.isdigit() and len(sender_str) <= 6:
            return 'Short Code'
        else:
            return 'Alphanumeric'
    
    df['sender_category'] = df['sender'].apply(categorize_sender)
    
    # Analysis by sender category
    sender_analysis = df.groupby(['sender_category', 'prediction']).size().unstack(fill_value=0)
    sender_percentages = df.groupby(['sender_category', 'prediction']).size().groupby(level=0).apply(lambda x: 100 * x / x.sum()).unstack(fill_value=0)
    
    print("Classification by Sender Type:")
    print(sender_analysis)
    print("\nPercentages:")
    print(sender_percentages.round(1))
    
    # Confidence analysis by sender type
    print(f"\nAverage Confidence by Sender Type:")
    confidence_by_sender = df.groupby('sender_category')['confidence'].mean().sort_values(ascending=False)
    for sender_type, avg_conf in confidence_by_sender.items():
        print(f"  {sender_type}: {avg_conf:.2f}")
    
    return sender_analysis, sender_percentages

def performance_metrics():
    """Calculate detailed performance metrics"""
    print(f"\nüìà PERFORMANCE METRICS")
    print("=" * 40)
    
    try:
        df = pd.read_csv("comprehensive_test_results_2000.csv")
    except FileNotFoundError:
        print("‚ùå Test results file not found.")
        return
    
    total_messages = len(df)
    
    # Classification distribution
    classification_dist = df['prediction'].value_counts()
    print("Final Classification Distribution:")
    for class_name, count in classification_dist.items():
        percentage = (count / total_messages) * 100
        print(f"  {class_name}: {count} ({percentage:.1f}%)")
    
    # Confidence distribution
    print(f"\nConfidence Score Distribution:")
    for prediction in ['LEGITIMATE', 'SPAM', 'FRAUD']:
        subset = df[df['prediction'] == prediction]
        if len(subset) > 0:
            avg_conf = subset['confidence'].mean()
            min_conf = subset['confidence'].min()
            max_conf = subset['confidence'].max()
            print(f"  {prediction}: Avg={avg_conf:.2f}, Range=[{min_conf:.2f}, {max_conf:.2f}]")
    
    # Potential issues
    print(f"\nPotential Issues to Monitor:")
    
    # Low confidence predictions
    low_confidence = df[df['confidence'] < 0.5]
    print(f"  Low confidence predictions (<0.5): {len(low_confidence)} ({len(low_confidence)/total_messages*100:.1f}%)")
    
    # Service codes classified as spam/fraud
    service_issues = df[
        (df['sender'].str.contains(r'^[A-Z]{2,6}-', na=False)) & 
        (df['prediction'] != 'LEGITIMATE')
    ]
    print(f"  Service codes flagged as threats: {len(service_issues)} ({len(service_issues)/total_messages*100:.1f}%)")
    
    # Unknown sender fraud rate
    unknown_senders = df[df['sender_category'] == 'Unknown/Kaggle']
    if len(unknown_senders) > 0:
        unknown_fraud_rate = len(unknown_senders[unknown_senders['prediction'] == 'FRAUD']) / len(unknown_senders) * 100
        print(f"  Unknown sender fraud rate: {unknown_fraud_rate:.1f}%")
    
    return classification_dist

def recommendations():
    """Generate recommendations based on analysis"""
    print(f"\nüí° RECOMMENDATIONS FOR IMPROVEMENT")
    print("=" * 50)
    
    edge_cases = analyze_edge_cases()
    sender_analysis, _ = sender_based_analysis()
    performance = performance_metrics()
    
    print(f"\nüìã Action Items:")
    
    if edge_cases['borderline_count'] > 50:
        print(f"1. üü° Review {edge_cases['borderline_count']} borderline cases to improve confidence")
    
    if edge_cases['service_spam_count'] > 10:
        print(f"2. üîß Tune model to reduce false positives on service messages ({edge_cases['service_spam_count']} cases)")
        print(f"   - Add stronger legitimate service patterns")
        print(f"   - Boost confidence for verified service codes")
    
    if edge_cases['phone_threats_count'] > 5:
        print(f"3. üì± Review phone number classifications ({edge_cases['phone_threats_count']} flagged)")
        print(f"   - Consider sender reputation scoring")
    
    fraud_rate = performance['FRAUD'] / sum(performance.values()) * 100
    if fraud_rate < 0.1:
        print(f"4. üîç Fraud detection rate is very low ({fraud_rate:.2f}%)")
        print(f"   - Consider if this reflects actual fraud prevalence")
        print(f"   - May need more aggressive fraud detection")
    
    spam_rate = performance['SPAM'] / sum(performance.values()) * 100
    if spam_rate > 15:
        print(f"5. üì¢ High spam detection rate ({spam_rate:.1f}%)")
        print(f"   - Review spam classifications for accuracy")
        print(f"   - Consider user preferences for promotional content")
    
    print(f"\n‚úÖ Overall Assessment:")
    print(f"   - System appears conservative (low false positive risk)")
    print(f"   - Good balance between classes")
    print(f"   - Ready for production deployment with monitoring")

def main():
    """Run complete detailed analysis"""
    print("üî¨ DETAILED ANALYSIS OF COMPREHENSIVE TEST RESULTS")
    print("=" * 70)
    
    recommendations()

if __name__ == "__main__":
    main()
